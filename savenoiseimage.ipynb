{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './-_000001.tif'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/zk-dell/fourier/fft_finetune/savenoiseimage.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Ba/home/zk-dell/fourier/fft_finetune/savenoiseimage.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmath\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Ba/home/zk-dell/fourier/fft_finetune/savenoiseimage.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mPIL\u001b[39;00m \u001b[39mimport\u001b[39;00m Image\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Ba/home/zk-dell/fourier/fft_finetune/savenoiseimage.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m I \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(Image\u001b[39m.\u001b[39;49mopen(\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m./-_000001.tif\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39mconvert(\u001b[39m'\u001b[39m\u001b[39mL\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Ba/home/zk-dell/fourier/fft_finetune/savenoiseimage.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m H\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39msize(I,\u001b[39m0\u001b[39m)  \u001b[39m#计算 X 的行数\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Ba/home/zk-dell/fourier/fft_finetune/savenoiseimage.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m W\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39msize(I,\u001b[39m1\u001b[39m)  \u001b[39m#计算 X 的列数\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/nzf/lib/python3.10/site-packages/PIL/Image.py:3092\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3089\u001b[0m     filename \u001b[39m=\u001b[39m fp\n\u001b[1;32m   3091\u001b[0m \u001b[39mif\u001b[39;00m filename:\n\u001b[0;32m-> 3092\u001b[0m     fp \u001b[39m=\u001b[39m builtins\u001b[39m.\u001b[39;49mopen(filename, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m   3093\u001b[0m     exclusive_fp \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   3095\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './-_000001.tif'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import convolve2d\n",
    "import math\n",
    "from PIL import Image\n",
    "I = np.array(Image.open(r'./-_000001.tif').convert('L'))\n",
    "H=np.size(I,0)  #计算 X 的行数\n",
    "W=np.size(I,1)  #计算 X 的列数\n",
    "\n",
    "M=np.array([[1, -2, 1], [-2, 4, -2], [1, -2, 1]])\n",
    "Sigma=sum(sum(abs(convolve2d(I, M))))\n",
    "\n",
    "\n",
    "Sigma=Sigma*np.sqrt(0.5*math.pi)/(6*(W-2)*(H-2))\n",
    "print(Sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "from collections.abc import Iterable\n",
    "\n",
    "import cv2\n",
    "import hiddenlayer as hl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from numpy.core.numeric import ones_like\n",
    "from PIL import Image\n",
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import scipy.io as sio\n",
    "import torchvision.transforms.functional\n",
    "from ffdnet.models import FFDNet\n",
    "from ffdnet.test_ffdnet_ipol import ffdnet_vdenoiser\n",
    "from loss import PSNR, SSIM\n",
    "from model.model import realFFT, realiFFT\n",
    "from SwinIR.SwinIR.net import SwinIR\n",
    "from model.unet import UNet\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readimg2amp(name, dim=(128,128),out_size=300):\n",
    "    transform = transforms.Resize(dim)\n",
    "    amp = Image.open(name)\n",
    "    amp = np.array(amp.convert('L'))\n",
    "    amp = amp.astype(np.float32)\n",
    "    amp = amp / np.max(amp)\n",
    "    amp = cv2.resize(amp, dim)\n",
    "    amp = torch.from_numpy(amp)\n",
    "    H = realFFT(window_size = 2048)\n",
    "    diffraction_I, _ = H(amp, torch.ones_like(amp), out_size)\n",
    "    diffraction_I = diffraction_I.unsqueeze(0).unsqueeze(0)\n",
    "    amp = amp.unsqueeze(0).unsqueeze(0)\n",
    "    return diffraction_I, amp\n",
    "def mkdir(path):\n",
    "    isExists = os.path.exists(path)\n",
    "    if not isExists:\n",
    "        os.makedirs(path)\n",
    "# I, O =  readimg2amp('ablation/emnist_A4_unet_5_lr=0.001/result/groundtruth.png')\n",
    "I, O =  readimg2amp('ablation/emnist_A4_unet_5_lr=0.001/result/groundtruth.png')\n",
    "mkdir('./baselineimg/')\n",
    "torchvision.utils.save_image(I, './baselineimg/L_I_300.png')\n",
    "torchvision.utils.save_image(O, './baselineimg/L_O.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1943) tensor(0.1943)\n"
     ]
    }
   ],
   "source": [
    "SNR = 0\n",
    "S = O.mean()\n",
    "N = S / 10**(SNR/20)\n",
    "noise =  torch.randn_like(O) * N\n",
    "Inoise = O + noise\n",
    "torchvision.utils.save_image(Inoise, './baselineimg/O_0dB.png')\n",
    "\n",
    "print(S,N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "from loss import PSNR, SSIM\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision.transforms import InterpolationMode\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from math import exp\n",
    "import numpy as np\n",
    "def findbestposition(O, I_pred, mse) :\n",
    "\n",
    "    # 定义搜索窗口大小和步长\n",
    "    window_size = 35  # 搜索窗口大小\n",
    "    stride = 1  # 步长\n",
    "    # 初始化最小差异和对应的平移量\n",
    "    min_diff = float('inf')\n",
    "    best_translation = (0, 0)\n",
    "    best_translated_I_pred = I_pred\n",
    "    # 遍历搜索窗口\n",
    "\n",
    "    for i in range(-window_size, window_size, stride):\n",
    "        for j in range(-window_size, window_size, stride):\n",
    "            # 平移图像\n",
    "            angle = 0\n",
    "            translated_I_pred = transforms.functional.affine(I_pred, translate = (i, j), angle=0, scale=1, shear=0) # type: ignore\n",
    "\n",
    "            # 计算均方误差\n",
    "            diff = mse(O, translated_I_pred)\n",
    "\n",
    "            # 如果找到更小的差异，更新最小差异和平移量\n",
    "            if diff < min_diff:\n",
    "                min_diff = diff\n",
    "                best_translation = (i, j)\n",
    "                best_translated_I_pred = translated_I_pred\n",
    "\n",
    "\n",
    "    return best_translated_I_pred, min_diff \n",
    "def gaussian(window_size, sigma):\n",
    "    gauss = torch.Tensor([exp(-(x - window_size//2)**2/float(2*sigma**2)) for x in range(window_size)])\n",
    "    return gauss/gauss.sum()\n",
    "\n",
    "\n",
    "def create_window(window_size, channel=1):\n",
    "    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n",
    "    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
    "    window = _2D_window.expand(channel, 1, window_size, window_size).contiguous()\n",
    "    return window\n",
    "\n",
    "\n",
    "def ssim(img1, img2, window_size=11, window=None, size_average=True, full=False, val_range=None):\n",
    "    # Value range can be different from 255. Other common ranges are 1 (sigmoid) and 2 (tanh).\n",
    "    if val_range is None:\n",
    "        if torch.max(img1) > 128:\n",
    "            max_val = 255\n",
    "        else:\n",
    "            max_val = 1\n",
    "\n",
    "        if torch.min(img1) < -0.5:\n",
    "            min_val = -1\n",
    "        else:\n",
    "            min_val = 0\n",
    "        L = max_val - min_val\n",
    "    else:\n",
    "        L = val_range\n",
    "\n",
    "    padd = 0\n",
    "    (_, channel, height, width) = img1.size()\n",
    "    if window is None:\n",
    "        real_size = min(window_size, height, width)\n",
    "        window = create_window(real_size, channel=channel).to(img1.device)\n",
    "\n",
    "    mu1 = F.conv2d(img1, window, padding=padd, groups=channel)\n",
    "    mu2 = F.conv2d(img2, window, padding=padd, groups=channel)\n",
    "\n",
    "    mu1_sq = mu1.pow(2)\n",
    "    mu2_sq = mu2.pow(2)\n",
    "    mu1_mu2 = mu1 * mu2\n",
    "\n",
    "    sigma1_sq = F.conv2d(img1 * img1, window, padding=padd, groups=channel) - mu1_sq\n",
    "    sigma2_sq = F.conv2d(img2 * img2, window, padding=padd, groups=channel) - mu2_sq\n",
    "    sigma12 = F.conv2d(img1 * img2, window, padding=padd, groups=channel) - mu1_mu2\n",
    "\n",
    "    C1 = (0.01 * L) ** 2\n",
    "    C2 = (0.03 * L) ** 2\n",
    "\n",
    "    v1 = 2.0 * sigma12 + C2\n",
    "    v2 = sigma1_sq + sigma2_sq + C2\n",
    "    cs = v1 / v2  # contrast sensitivity\n",
    "\n",
    "    ssim_map = ((2 * mu1_mu2 + C1) * v1) / ((mu1_sq + mu2_sq + C1) * v2)\n",
    "\n",
    "    if size_average:\n",
    "        cs = cs.mean()\n",
    "        ret = ssim_map.mean()\n",
    "    else:\n",
    "        cs = cs.mean(1).mean(1).mean(1)\n",
    "        ret = ssim_map.mean(1).mean(1).mean(1)\n",
    "\n",
    "    if full:\n",
    "        return ret, cs\n",
    "    return ret\n",
    "\n",
    "\n",
    "def msssim(img1, img2, window_size=11, size_average=True, val_range=None, normalize=None):\n",
    "    device = img1.device\n",
    "    weights = torch.FloatTensor([0.0448, 0.2856, 0.3001, 0.2363, 0.1333]).to(device)\n",
    "    levels = weights.size()[0]\n",
    "    ssims = []\n",
    "    mcs = []\n",
    "    for _ in range(levels):\n",
    "        sim, cs = ssim(img1, img2, window_size=window_size, size_average=size_average, full=True, val_range=val_range)\n",
    "\n",
    "        # Relu normalize (not compliant with original definition)\n",
    "        if normalize == \"relu\":\n",
    "            ssims.append(torch.relu(sim))\n",
    "            mcs.append(torch.relu(cs))\n",
    "        else:\n",
    "            ssims.append(sim)\n",
    "            mcs.append(cs)\n",
    "\n",
    "        img1 = F.avg_pool2d(img1, (2, 2))\n",
    "        img2 = F.avg_pool2d(img2, (2, 2))\n",
    "\n",
    "    ssims = torch.stack(ssims)\n",
    "    mcs = torch.stack(mcs)\n",
    "\n",
    "    # Simple normalize (not compliant with original definition)\n",
    "    # TODO: remove support for normalize == True (kept for backward support)\n",
    "    if normalize == \"simple\" or normalize == True:\n",
    "        ssims = (ssims + 1) / 2\n",
    "        mcs = (mcs + 1) / 2\n",
    "\n",
    "    pow1 = mcs ** weights\n",
    "    pow2 = ssims ** weights\n",
    "\n",
    "    # From Matlab implementation https://ece.uwaterloo.ca/~z70wang/research/iwssim/\n",
    "    output = torch.prod(pow1[:-1]) * pow2[-1]\n",
    "    return output\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findbestposition(O, I_pred, mse) :\n",
    "\n",
    "    # 定义搜索窗口大小和步长\n",
    "    window_size = 35  # 搜索窗口大小\n",
    "    stride = 1  # 步长\n",
    "    # 初始化最小差异和对应的平移量\n",
    "    min_diff = float('inf')\n",
    "    best_translation = (0, 0)\n",
    "    best_translated_I_pred = I_pred\n",
    "    # 遍历搜索窗口\n",
    "\n",
    "    for i in range(-window_size, window_size, stride):\n",
    "        for j in range(-window_size, window_size, stride):\n",
    "            # 平移图像\n",
    "            angle = 0\n",
    "            translated_I_pred = transforms.functional.affine(I_pred, translate = (i, j), angle=0, scale=1, shear=0) # type: ignore\n",
    "\n",
    "            # 计算均方误差\n",
    "            diff = mse(O, translated_I_pred)\n",
    "\n",
    "            # 如果找到更小的差异，更新最小差异和平移量\n",
    "            if diff < min_diff:\n",
    "                min_diff = diff\n",
    "                best_translation = (i, j)\n",
    "                best_translated_I_pred = translated_I_pred\n",
    "\n",
    "\n",
    "    return best_translated_I_pred, min_diff \n",
    "\n",
    "def ssim(img1, img2, window_size=11, window=None, size_average=True, full=False, val_range=None):\n",
    "    # Value range can be different from 255. Other common ranges are 1 (sigmoid) and 2 (tanh).\n",
    "    if val_range is None:\n",
    "        if torch.max(img1) > 128:\n",
    "            max_val = 255\n",
    "        else:\n",
    "            max_val = 1\n",
    "\n",
    "        if torch.min(img1) < -0.5:\n",
    "            min_val = -1\n",
    "        else:\n",
    "            min_val = 0\n",
    "        L = max_val - min_val\n",
    "    else:\n",
    "        L = val_range\n",
    "\n",
    "    padd = 0\n",
    "    (_, channel, height, width) = img1.size()\n",
    "    if window is None:\n",
    "        real_size = min(window_size, height, width)\n",
    "        window = create_window(real_size, channel=channel).to(img1.device)\n",
    "\n",
    "    mu1 = F.conv2d(img1, window, padding=padd, groups=channel)\n",
    "    mu2 = F.conv2d(img2, window, padding=padd, groups=channel)\n",
    "\n",
    "    mu1_sq = mu1.pow(2)\n",
    "    mu2_sq = mu2.pow(2)\n",
    "    mu1_mu2 = mu1 * mu2\n",
    "\n",
    "    sigma1_sq = F.conv2d(img1 * img1, window, padding=padd, groups=channel) - mu1_sq\n",
    "    sigma2_sq = F.conv2d(img2 * img2, window, padding=padd, groups=channel) - mu2_sq\n",
    "    sigma12 = F.conv2d(img1 * img2, window, padding=padd, groups=channel) - mu1_mu2\n",
    "\n",
    "    C1 = (0.01 * L) ** 2\n",
    "    C2 = (0.03 * L) ** 2\n",
    "\n",
    "    v1 = 2.0 * sigma12 + C2\n",
    "    v2 = sigma1_sq + sigma2_sq + C2\n",
    "    cs = v1 / v2  # contrast sensitivity\n",
    "\n",
    "    ssim_map = ((2 * mu1_mu2 + C1) * v1) / ((mu1_sq + mu2_sq + C1) * v2)\n",
    "\n",
    "    if size_average:\n",
    "        cs = cs.mean()\n",
    "        ret = ssim_map.mean()\n",
    "    else:\n",
    "        cs = cs.mean(1).mean(1).mean(1)\n",
    "        ret = ssim_map.mean(1).mean(1).mean(1)\n",
    "\n",
    "    if full:\n",
    "        return ret, cs\n",
    "    return ret\n",
    "\n",
    "\n",
    "def msssim(img1, img2, window_size=11, size_average=True, val_range=None, normalize=None):\n",
    "    device = img1.device\n",
    "    weights = torch.FloatTensor([0.0448, 0.2856, 0.3001, 0.2363, 0.1333]).to(device)\n",
    "    levels = weights.size()[0]\n",
    "    ssims = []\n",
    "    mcs = []\n",
    "    for _ in range(levels):\n",
    "        sim, cs = ssim(img1, img2, window_size=window_size, size_average=size_average, full=True, val_range=val_range)\n",
    "\n",
    "        # Relu normalize (not compliant with original definition)\n",
    "        if normalize == \"relu\":\n",
    "            ssims.append(torch.relu(sim))\n",
    "            mcs.append(torch.relu(cs))\n",
    "        else:\n",
    "            ssims.append(sim)\n",
    "            mcs.append(cs)\n",
    "\n",
    "        img1 = F.avg_pool2d(img1, (2, 2))\n",
    "        img2 = F.avg_pool2d(img2, (2, 2))\n",
    "\n",
    "    ssims = torch.stack(ssims)\n",
    "    mcs = torch.stack(mcs)\n",
    "\n",
    "    # Simple normalize (not compliant with original definition)\n",
    "    # TODO: remove support for normalize == True (kept for backward support)\n",
    "    if normalize == \"simple\" or normalize == True:\n",
    "        ssims = (ssims + 1) / 2\n",
    "        mcs = (mcs + 1) / 2\n",
    "\n",
    "    pow1 = mcs ** weights\n",
    "    pow2 = ssims ** weights\n",
    "\n",
    "    # From Matlab implementation https://ece.uwaterloo.ca/~z70wang/research/iwssim/\n",
    "    output = torch.prod(pow1[:-1]) * pow2[-1]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./figure/noise/0/E_O.png PSNR=inf,SSIM=1,VMSE=0.0000,SSIM2=1.0000,ms_ssim=1.0000\n",
      "./figure/noise/0/aCDI_0.png PSNR=12.31,SSIM=0.4785,VMSE=0.0587,SSIM2=0.4071,ms_ssim=0.5872\n",
      "./figure/noise/0/aHIO_0.png PSNR=9.559,SSIM=0.5475,VMSE=0.1107,SSIM2=0.4819,ms_ssim=0.4489\n"
     ]
    }
   ],
   "source": [
    "file='./figure/noise/0/'\n",
    "transfrom0 = transforms.ToTensor()\n",
    "img_name = {}\n",
    "img={}\n",
    "\n",
    "img_name[0]=file + 'E_O.png'\n",
    "img_name[1]=file + 'aCDI_0.png'\n",
    "img_name[2]=file + 'aHIO_0.png'\n",
    "for i in range(0,3):\n",
    "    img[i]= transfrom0(Image.open(img_name[i]).convert('L'))\n",
    "PSNRval={}\n",
    "SSIMval={}\n",
    "mPSNR = PSNR()\n",
    "mSSIM = SSIM()\n",
    "bestimg={}\n",
    "crop = transforms.CenterCrop(128)\n",
    "mse = nn.MSELoss().cuda()\n",
    "for i in range(0,3):\n",
    "    bestimg[i], vmse = findbestposition(img[0], img[i], mse)\n",
    "    PSNRval[i]= mPSNR(bestimg[i], img[0])\n",
    "    SSIMval[i]= mSSIM(bestimg[i].unsqueeze(0), img[0].unsqueeze(0))\n",
    "    ssim_val = ssim(bestimg[i].unsqueeze(0), img[0].unsqueeze(0)) # return (N,)\n",
    "    ms_ssim_val = msssim(bestimg[i].unsqueeze(0), img[0].unsqueeze(0)) #(N,\n",
    "    print(img_name[i],'PSNR=%.4g,SSIM=%.4g,VMSE=%.4f,SSIM2=%.4f,ms_ssim=%.4f' %(PSNRval[i],SSIMval[i],vmse,ssim_val,ms_ssim_val))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nzf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 (main, Mar 31 2022, 08:41:55) [GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0c3379aa285f3a02b946fbf4e88d8c75f02f656d5a66772bec050e8f35171cb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
